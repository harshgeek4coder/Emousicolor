# -*- coding: utf-8 -*-
"""SER-Neural Net Training.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nKse5k2aPBiQbrLwQyvX6-1iAfi5_6NE
"""

from google.colab import drive
drive.mount('/content/gdrive')

!pip install plotly

import keras
from keras.preprocessing.image import ImageDataGenerator
from keras.applications.vgg16 import VGG16
from keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization, Dense, Conv1D
from keras.models import Model, Sequential
from keras.callbacks import ModelCheckpoint, EarlyStopping
from keras.utils import np_utils

import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.decomposition import PCA

class NeuralNet():
    def __init__(self, train_data_path, test_data_path, target_size=(0,0), is_image_data=True, epoch=None):
        self.is_image_data = is_image_data
        self.train_data_path = train_data_path
        self.test_data_path = test_data_path
        if((self.is_image_data)&(epoch==None)): self.epoch = 60
        elif((~self.is_image_data)&(epoch==None)): self.epoch = 600
        else: self.epoch = epoch
        self.target_size = target_size
        
    def dataset_generator(self, train_path, test_path, color_mode, class_mode, shuffle=True):
       
        traindata = ImageDataGenerator().flow_from_directory(directory=train_path, target_size=self.target_size, class_mode=class_mode,
                                                             color_mode=color_mode, shuffle=shuffle)
        testdata = ImageDataGenerator().flow_from_directory(directory=test_path, target_size=self.target_size, class_mode=class_mode,
                                                             color_mode=color_mode, shuffle=shuffle)

        return traindata, testdata
    
    def dataset_generator_cnn(self, train_path, test_path):
        train_data = pd.read_csv(train_path)
        test_data = pd.read_csv(test_path)

        
        scaler = StandardScaler()
        scaler.fit(train_data.drop(['label','name'],axis=1))
        x_train = scaler.transform(train_data.drop(['label','name'],axis=1))
        x_test = scaler.transform(test_data.drop(['label','name'],axis=1))

        pca = PCA(.95)

        train_pca = pca.fit_transform(x_train)
        test_pca = pca.transform(x_test)

       
        y_train = np.array(train_data.label)
        y_test = np.array(test_data.label)
        lb = LabelEncoder()
        y_train = np_utils.to_categorical(lb.fit_transform(y_train))
        y_test = np_utils.to_categorical(lb.transform(y_test))
        
        
        x_train = np.expand_dims(train_pca, axis=2)
        x_test = np.expand_dims(test_pca, axis=2)
        
        return x_train, y_train, x_test, y_test
        
    def get_model(self):
        
        print(self.model.summary())
        
    def fit(self, model, optimizer, loss, output_path):
      
        self.model = model
        self.get_model()
        self.model.compile(loss=loss, optimizer=optimizer, metrics=['acc'])
        
       
        checkpoint = ModelCheckpoint(output_path, monitor='val_acc', verbose=1, save_best_only=True, 
                                     save_weights_only=False, mode='auto', period=1)
        
       
        early = EarlyStopping(monitor='val_acc', min_delta=0, patience=20, verbose=1, mode='auto')
          
        if self.is_image_data:
            traindata, testdata = self.dataset_generator(self.train_data_path, self.test_data_path, color_mode='rgb', 
                                                         class_mode='categorical', shuffle=True)
            self.hist = self.model.fit_generator(generator=traindata, validation_data=testdata, epochs=self.epoch,
                                                 callbacks=[checkpoint,early])
        else:
            x_train, y_train, x_test, y_test = self.dataset_generator_cnn(self.train_data_path, self.test_data_path)
            self.hist = self.model.fit(x_train, y_train, batch_size=16, epochs=self.epoch,
                                       validation_data=(x_test, y_test), callbacks=[checkpoint, early])
            self.results=model.evaluate(x_test,y_test)
            print("test loss, test acc:", self.results)
       
        self.accplot = self.get_plot([self.hist.history['acc'],self.hist.history['val_acc']],'a')
        self.lossplot = self.get_plot([self.hist.history['loss'],self.hist.history['val_loss']],'l')
        self.final_plot([self.hist.history['acc'],self.hist.history['val_acc'],self.hist.history['loss'],self.hist.history['val_loss']])
    
    def get_plot(self, metric, typeof):
        if(typeof=='a'):
            title = "Model Accuracy"
            ylabel = "Accuracy"
            xlabel = "Epoch"
            legend = ["Accuracy","Validation Accuracy"]
        else:
            title = "Model Loss"
            ylabel = "Loss"
            xlabel = "Epoch"
            legend = ["Loss","Validation Loss"]  
        plt.figure(figsize=(20,10))
        plt.plot(metric[0])
        plt.plot(metric[1])
        plt.title(title)
        plt.ylabel(ylabel)
        plt.xlabel(xlabel)
        plt.legend(legend)
        return plt

      
    def final_plot(self, metric):
      

       metric=[self.hist.history['acc'],self.hist.history['val_acc'],self.hist.history['loss'],self.hist.history['val_loss']]         
       legend = ["Accuracy","Validation Accuracy","Loss","Validation Loss"]  
       plt.figure(figsize=(20,10))
       plt.title("Training and Validation Loss And Accuracy of SER Dataset")
       plt.plot(metric[0])
       plt.plot(metric[1])
       plt.plot(metric[2])
       plt.plot(metric[3])
      
       plt.legend(legend)
       return plt







from keras import regularizers
from tensorflow.keras import optimizers
import tensorflow as tf
tf.keras.backend.clear_session()

model = Sequential()
model.add(Conv1D(256, 8, padding='same',input_shape=(66,1)))
model.add(Activation('relu'))
model.add(Conv1D(256, 8, padding='same'))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(Dropout(0.6))
model.add(Conv1D(128, 8, padding='same'))
model.add(Activation('relu'))
model.add(Conv1D(128, 8, padding='same'))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(Dropout(0.6))
model.add(Conv1D(64, 8, padding='same'))
model.add(Activation('relu'))
model.add(Conv1D(64, 8, padding='same'))
model.add(Activation('relu'))
model.add(Flatten())
model.add(Dense(64, activation='relu'))
model.add(Activation('relu'))
model.add(Dropout(0.25))
model.add(Dense(32, activation='relu'))
model.add(Activation('relu'))
model.add(Dropout(0.25))
model.add(Dense(16))
model.add(Activation('softmax'))

optimizer = tf.keras.optimizers.Adam(
    learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,
    name='Adam'
)

neuralnet = NeuralNet("/content/gdrive/MyDrive/data_spec/waves/train_wave_features.csv", "/content/gdrive/MyDrive/data_spec/waves/test_wave_features.csv", is_image_data=False, epoch=35)
neuralnet.fit(model, optimizer, 'categorical_crossentropy', "model/CNN with Feature Array.h5")



## For CNN with Dataframe of MFCC, MEL Scale, and Chroma
## 71 % Accuracy
from keras import regularizers
from tensorflow.keras import optimizers
import tensorflow as tf
tf.keras.backend.clear_session()

model = Sequential()
model.add(Conv1D(256, 8, padding='same',input_shape=(66,1)))
model.add(Activation('relu'))
model.add(Conv1D(256, 8, padding='same'))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(Dropout(0.6))
model.add(Conv1D(128, 8, padding='same'))
model.add(Activation('relu'))
model.add(Conv1D(128, 8, padding='same'))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(Dropout(0.6))
model.add(Conv1D(64, 8, padding='same'))
model.add(Activation('relu'))
model.add(Conv1D(64, 8, padding='same'))
model.add(Activation('relu'))
model.add(Dropout(0.4))
model.add(Flatten())
model.add(Dense(256, activation='relu'))
model.add(Activation('relu'))
model.add(Dropout(0.4))
model.add(Dense(128, activation='relu'))
model.add(Activation('relu'))
model.add(Dropout(0.2))
model.add(Dense(16))
model.add(Activation('softmax'))

optimizer = tf.keras.optimizers.Adam(
    learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,
    name='Adam'
)

neuralnet = NeuralNet("/content/gdrive/MyDrive/data_spec/waves/train_wave_features.csv", "/content/gdrive/MyDrive/data_spec/waves/test_wave_features.csv", is_image_data=False, epoch=35)
neuralnet.fit(model, optimizer, 'categorical_crossentropy', "model/CNN with Feature Array.h5")

model.save("/content/gdrive/MyDrive/CNN-SER-Arch.h5")
model.save_weights("/content/gdrive/MyDrive/CNN-SER-Arch_Weights.h5")

## For CNN with Dataframe of MFCC, MEL Scale, and Chroma
## 73 % Accuracy-wrkn
from keras import regularizers
from tensorflow.keras import optimizers
import tensorflow as tf
tf.keras.backend.clear_session()

model = Sequential()
model.add(Conv1D(256, 8, padding='same',input_shape=(66,1)))
model.add(Activation('relu'))
model.add(Conv1D(256, 8, padding='same'))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(Dropout(0.6))
model.add(Conv1D(128, 8, padding='same'))
model.add(Activation('relu'))
model.add(Conv1D(128, 8, padding='same'))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(Dropout(0.6))
model.add(Conv1D(64, 8, padding='same'))
model.add(Activation('relu'))
model.add(Conv1D(64, 8, padding='same'))
model.add(Activation('relu'))
model.add(Dropout(0.4))
model.add(Flatten())
model.add(Dense(256, activation='relu'))
model.add(Activation('relu'))
model.add(Dense(128, activation='relu'))
model.add(Activation('relu'))
model.add(Dropout(0.2))
model.add(Dense(16))
model.add(Activation('softmax'))

optimizer = tf.keras.optimizers.Adam(
    learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,
    name='Adam'
)

neuralnet = NeuralNet("/content/gdrive/MyDrive/data_spec/waves/train_wave_features.csv", "/content/gdrive/MyDrive/data_spec/waves/test_wave_features.csv", is_image_data=False, epoch=50)
neuralnet.fit(model, optimizer, 'categorical_crossentropy', "model/CNN with Feature Array.h5")

#model.save("/content/gdrive/MyDrive/CNN-SER-Arch.h5")
#model.save_weights("/content/gdrive/MyDrive/CNN-SER-Arch_Weights.h5")



## For CNN with Dataframe of MFCC, MEL Scale, and Chroma
## 76 in 52 nd  epoch % Accuracy-wrkn
from keras import regularizers
from tensorflow.keras import optimizers
import tensorflow as tf
tf.keras.backend.clear_session()

model = Sequential()
model.add(Conv1D(256, 8, padding='same',input_shape=(66,1)))
model.add(Activation('relu'))
model.add(Conv1D(256, 8, padding='same'))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(Dropout(0.6))
model.add(Conv1D(128, 8, padding='same'))
model.add(Activation('relu'))
model.add(Conv1D(128, 8, padding='same'))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(Dropout(0.4))


model.add(Flatten())
model.add(Dense(256, activation='relu'))
model.add(Activation('relu'))
model.add(Dense(256, activation='relu'))
#model.add(Activation('relu'))


model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(Dropout(0.4))
model.add(Dense(16))
model.add(Activation('softmax'))

optimizer = tf.keras.optimizers.Adam(
    learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,
    name='Adam'
)

neuralnet = NeuralNet("/content/gdrive/MyDrive/data_spec/waves/train_wave_features.csv", "/content/gdrive/MyDrive/data_spec/waves/test_wave_features.csv", is_image_data=False, epoch=62)
neuralnet.fit(model, optimizer, 'categorical_crossentropy', "model/CNN with Feature Array.h5")

#model.save("/content/gdrive/MyDrive/CNN-SER-Arch.h5")
#model.save_weights("/content/gdrive/MyDrive/CNN-SER-Arch_Weights.h5")



## For CNN with Dataframe of MFCC, MEL Scale, and Chroma
## 77% at 61 st epoch

from keras import regularizers
from tensorflow.keras import optimizers
import tensorflow as tf
tf.keras.backend.clear_session()

model = Sequential()
model.add(Conv1D(256, 8, padding='same',input_shape=(66,1)))
model.add(Activation('selu'))
model.add(Conv1D(256, 8, padding='same'))
model.add(BatchNormalization())
model.add(Activation('selu'))
model.add(Dropout(0.6))
model.add(Conv1D(128, 8, padding='same'))
model.add(Activation('selu'))
model.add(Conv1D(128, 8, padding='same'))
model.add(BatchNormalization())
model.add(Activation('selu'))
model.add(Dropout(0.6))


model.add(Flatten())
model.add(Dense(256, activation='selu'))
model.add(Activation('selu'))
model.add(Dense(128, activation='selu'))
model.add(Activation('selu'))

model.add(BatchNormalization())
model.add(Activation('selu'))
model.add(Dropout(0.6))
model.add(Dense(16))
model.add(Activation('softmax'))

optimizer = tf.keras.optimizers.Adam(
    learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,
    name='Adam'
)

neuralnet = NeuralNet("/content/gdrive/MyDrive/data_spec/waves/train_wave_features.csv", "/content/gdrive/MyDrive/data_spec/waves/test_wave_features.csv", is_image_data=False, epoch=100)
neuralnet.fit(model, optimizer, 'categorical_crossentropy', "model/CNN with Feature Array.h5")

#model.save("/content/gdrive/MyDrive/CNN-SER-Arch.h5")
#model.save_weights("/content/gdrive/MyDrive/CNN-SER-Arch_Weights.h5")









"""## Test Mode:"""

## For CNN with Dataframe of MFCC, MEL Scale, and Chroma
## 77% at 61 st epoch

from keras import regularizers
from tensorflow.keras import optimizers
import tensorflow as tf
tf.keras.backend.clear_session()

model = Sequential()
model.add(Conv1D(256, 8, padding='same',input_shape=(66,1)))
model.add(Activation('selu'))
model.add(Conv1D(256, 8, padding='same'))
model.add(BatchNormalization())
model.add(Activation('selu'))
model.add(Dropout(0.6))
model.add(Conv1D(128, 8, padding='same'))
model.add(Activation('selu'))
model.add(Conv1D(128, 8, padding='same'))
model.add(BatchNormalization())
model.add(Activation('selu'))
model.add(Dropout(0.6))


model.add(Flatten())
model.add(Dense(256, activation='selu'))
model.add(Activation('selu'))
model.add(Dense(128, activation='selu'))
model.add(Activation('selu'))

model.add(BatchNormalization())
model.add(Activation('selu'))
model.add(Dropout(0.6))
model.add(Dense(16))
model.add(Activation('softmax'))

optimizer = tf.keras.optimizers.Adam(
    learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,
    name='Adam'
)

neuralnet = NeuralNet("/content/gdrive/MyDrive/data_spec/waves/train_wave_features.csv", "/content/gdrive/MyDrive/data_spec/waves/test_wave_features.csv", is_image_data=False, epoch=100)
neuralnet.fit(model, optimizer, 'categorical_crossentropy', "model/CNN with Feature Array.h5")


#model.save("/content/gdrive/MyDrive/CNN-SER-Arch.h5")
#model.save_weights("/content/gdrive/MyDrive/CNN-SER-Arch_Weights.h5")

#import tensorflow as tf
from keras.utils import plot_model
plot_model(model, to_file='model_plot.png', show_layer_names=True)









## For CNN with Dataframe of MFCC, MEL Scale, and Chroma
## 77% at 61 st epoch

from keras import regularizers
from tensorflow.keras import optimizers
import tensorflow as tf
from keras.layers import GlobalMaxPooling1D
tf.keras.backend.clear_session()

model = Sequential()

model.add(Conv1D(512, 8, padding='same',input_shape=(66,1)))
model.add(Activation('selu'))
model.add(Dropout(0.2))
model.add(Conv1D(512, 8, padding='same'))
model.add(BatchNormalization())
model.add(Activation('selu'))
model.add(Dropout(0.6))
model.add(Conv1D(256, 8, padding='same'))
model.add(Activation('selu'))
model.add(Dropout(0.2))
model.add(Conv1D(256, 8, padding='same'))
model.add(BatchNormalization())
model.add(Activation('selu'))
model.add(Dropout(0.6))
model.add(Conv1D(128, 8, padding='same'))
model.add(Activation('selu'))
model.add(Dropout(0.2))
model.add(Conv1D(128, 8, padding='same'))
model.add(BatchNormalization())
model.add(Activation('selu'))
model.add(Dropout(0.6))


model.add(Flatten())
model.add(Dense(512, activation='selu'))
model.add(Activation('selu'))
model.add(Dropout(0.2))
model.add(Dense(256, activation='selu'))
model.add(Activation('selu'))
model.add(Dropout(0.2))
model.add(Dense(128, activation='selu'))
model.add(Activation('selu'))
model.add(Dropout(0.2))

model.add(BatchNormalization())
model.add(Activation('selu'))
model.add(Dropout(0.6))
model.add(Dense(16))
model.add(Activation('softmax'))

optimizer = tf.keras.optimizers.Adam(
    learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,
    name='Adam'
)

neuralnet = NeuralNet("/content/gdrive/MyDrive/data_spec/waves/train_wave_features.csv", "/content/gdrive/MyDrive/data_spec/waves/test_wave_features.csv", is_image_data=False, epoch=100)
neuralnet.fit(model, optimizer, 'categorical_crossentropy', "model/CNN with Feature Array.h5")

#model.save("/content/gdrive/MyDrive/CNN-SER-Arch.h5")
#model.save_weights("/content/gdrive/MyDrive/CNN-SER-Arch_Weights.h5")

